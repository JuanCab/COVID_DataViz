{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting and Condensing COVID Data (Version 2)\n",
    "\n",
    "This Jupyter notebook reads in the data from a variety of online sources that we need for the COVID Data Vizualization Project.  Some attempts are made to produce simpler to work with output files.  Depending on how long this notebook takes\n",
    "to execute, it may not make sense to 'condense' the data first.\n",
    "\n",
    "**Verion 2 Release Note**: This version of the Notebook moved the routines for retrieving and processing data to a local python library.  This allowed re-use of those functions in generating test data.  I confirmed output was IDENTICAL to the Version 1 output before 'deprecating' version 1 to a renamed file.\n",
    "\n",
    "- **A Note about FIPS:** Some of the data includes FIPS codes (a standard geographic identifier) which should ease the process of cross-matching of data.  Clay County is 27027 and Cass County is 38017.  Minnesota is 27, North Dakota is 38."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This forces a reload of any external library file if it changes.  \n",
    "# Useful when developing external libraries since otherwise Jupyter \n",
    "# will not re-import any library without restarting the python kernel.\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import git\n",
    "\n",
    "# Import COVID data retrieval routines from external python library\n",
    "import COVID_collectors as COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define variables of interest below\n",
    "data_dir = 'our_data/'    # Data directory for files we created\n",
    "\n",
    "## Define FIPS corresponding to various local areas\n",
    "ClayFIPS = 27027\n",
    "CassFIPS = 38017\n",
    "MNFIPS = 27\n",
    "NDFIPS = 38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  John Hopkins Cases Data (FIPS Present)\n",
    "    - https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases\n",
    "\n",
    "This dataset is part of COVID-19 Pandemic Novel Corona Virus (COVID-19)\n",
    "epidemiological data since 22 January 2020. The JHU CCSE maintains the data on the 2019 Novel\n",
    "Coronavirus COVID-19 (2019-nCoV) Data Repository on Github\n",
    "(https://github.com/CSSEGISandData/COVID-19). \n",
    "I have also folded in US Census Bureau population informationf for these counties/states.\n",
    "\n",
    "### Notes about the dataframes:\n",
    "- County level daily confirmed/deaths/recovered data files changes format\n",
    "  several times before April 23, 2020, so I didn't include that data. \n",
    "- State level daily data files contain some additional data that county level\n",
    "  files do not contain, notably Incident_Rate, People_Tested,\n",
    "  People_Hospitalized, Mortality_Rate, Testing_Rate, and Hospitalization_Rate. \n",
    "  However, it only exists starting April 12, 2020.\n",
    "- Time-series data files contain more limited data (only confirmed cases and\n",
    "  deaths) and are essentially redundant data compared to the daily files, so\n",
    "  combining the daily files makes sense.\n",
    "\n",
    "**Suggested Citations**: the COVID-19 Data Repository by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University.  Population data from U.S. Census Bureau, Population Division (Release Date: March 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "## Retrieve the US Census data and then John Hopkins data\n",
    "##\n",
    "\n",
    "# Retrieve needed Census Bureau data first\n",
    "(cnty_pop_df, state_pop_df) = COVID.retrieve_census_population_data()\n",
    "\n",
    "# Retrieve John Hopkins data\n",
    "(ts_us_confirmed_df, ts_us_dead_df, combined_cnty_df, combined_state_df) = COVID.retrieve_John_Hopkins_data(cnty_pop_df, state_pop_df)\n",
    "\n",
    "#\n",
    "# Save the county and state-level processed daily datafra,es into CSV files\n",
    "#\n",
    "combined_datafile = data_dir + \"countylevel_combinedCDR.csv\"\n",
    "combined_cnty_df.to_csv(combined_datafile, index=False)\n",
    "\n",
    "combined_datafile = data_dir + \"statelevel_combinedCDR.csv\"\n",
    "combined_state_df.to_csv(combined_datafile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Plot the time series datafiles to experiment with them.  These only contain Deaths and Confirmed cases,\n",
    "## so I suspect we won't keep them, since I build the same data from the daily data files simultaneously retrieved from\n",
    "## John Hopkins.\n",
    "##\n",
    "\n",
    "# We could transpose the dataframe to allow easier extraction of time series data on a per county level\n",
    "tmp_df = ts_us_confirmed_df[ (ts_us_confirmed_df['Province_State'] == 'Minnesota') & (ts_us_confirmed_df['Admin2'] == 'Clay') ].T\n",
    "tmp_df.rename(columns={ tmp_df.columns[0]: \"confirmed\" }, inplace = True)\n",
    "confirmed_clay = tmp_df[tmp_df.index.str.match('[0-9]*/[0-9]*/[0-9]*')]  # Use pattern matching to find real dates and include\n",
    "\n",
    "tmp_df = ts_us_dead_df[ (ts_us_confirmed_df['Province_State'] == 'Minnesota') & (ts_us_confirmed_df['Admin2'] == 'Clay') ].T\n",
    "tmp_df.rename(columns={ tmp_df.columns[0]: \"dead\" }, inplace = True)\n",
    "dead_clay = tmp_df[tmp_df.index.str.match('[0-9]*/[0-9]*/[0-9]*')] # Use pattern matching to find real dates and include\n",
    "\n",
    "# Merge the confirmed ill and dead into one dataframe (would like recovered too, but that's not in\n",
    "# these times series files).  \n",
    "merged_clay = confirmed_clay.merge(dead_clay, left_index=True, right_index=True)\n",
    "plot = merged_clay.plot(figsize=(10,8))\n",
    "xlabel = plt.xlabel('Date')\n",
    "ylabel = plt.title('Confirmed COVID Infections and Deaths')\n",
    "title = plt.title('Clay County Confirmed COVID Infections and Deaths')\n",
    "\n",
    "# NOTE: This is using PANDAS to do the plotting, it will be a lot more flexible to extra data from Pandas and then\n",
    "# use matplotlib to make the plots.  For one thing, we could add labels to the plot more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show demonstrations of plotting this data here by producing plots of data for Cass and Clay counties and North Dakota and Minnesota\n",
    "\n",
    "#\n",
    "# I will pull the data to plot into numpy arrays (notice I have to use [0] because it comes out at list of lists even for single row)\n",
    "#\n",
    "\n",
    "# County-level data for plotting\n",
    "dates_cty = np.array(combined_cnty_df[(combined_cnty_df['FIPS'] == ClayFIPS)]['Dates'].to_list()[0], dtype='datetime64')\n",
    "clay_deaths = np.array(combined_cnty_df[(combined_cnty_df['FIPS'] == ClayFIPS)]['Deaths'].to_list()[0],dtype='int')\n",
    "clay_death_rate = (clay_deaths/combined_cnty_df[(combined_cnty_df['FIPS'] == ClayFIPS)]['PopEst2019'].values)*100000\n",
    "cass_deaths = np.array(combined_cnty_df[(combined_cnty_df['FIPS'] == CassFIPS)]['Deaths'].to_list()[0],dtype='int')\n",
    "cass_death_rate = (cass_deaths/combined_cnty_df[(combined_cnty_df['FIPS'] == CassFIPS)]['PopEst2019'].values)*100000\n",
    "clay_confirmed = np.array(combined_cnty_df[(combined_cnty_df['FIPS'] == ClayFIPS)]['Confirmed'].to_list()[0],dtype='int')\n",
    "clay_confirmed_rate = (clay_confirmed/combined_cnty_df[(combined_cnty_df['FIPS'] == ClayFIPS)]['PopEst2019'].values)*100000\n",
    "cass_confirmed = np.array(combined_cnty_df[(combined_cnty_df['FIPS'] == CassFIPS)]['Confirmed'].to_list()[0],dtype='int')\n",
    "cass_confirmed_rate = (cass_confirmed/combined_cnty_df[(combined_cnty_df['FIPS'] == CassFIPS)]['PopEst2019'].values)*100000\n",
    "\n",
    "# Set up a figure of 2 x 2 plots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15,10))\n",
    "\n",
    "# Plot up deaths and death rates as plots 0 and 1\n",
    "this_axs = axs[0, 0]  # Row 0, column 0\n",
    "this_axs.plot(dates_cty, clay_deaths, label='Clay County')\n",
    "this_axs.plot(dates_cty, cass_deaths, label='Cass County')\n",
    "legend = this_axs.legend()\n",
    "xlabel = this_axs.set_xlabel(\"Date\")\n",
    "ylabel = this_axs.set_ylabel(\"Number\")\n",
    "title = this_axs.set_title(\"COVID Deaths\")\n",
    "\n",
    "this_axs = axs[1, 0]  # Row 1, column 0\n",
    "this_axs.plot(dates_cty, clay_death_rate, label='Clay County')\n",
    "this_axs.plot(dates_cty, cass_death_rate, label='Cass County')\n",
    "legend = this_axs.legend()\n",
    "xlabel = this_axs.set_xlabel(\"Date\")\n",
    "ylabel = this_axs.set_ylabel(\"Rate / 100000 people\")\n",
    "title = this_axs.set_title(\"COVID Deaths per 100,000 people\")\n",
    "\n",
    "# Plot up confirmed infections and infection rates as plots 2 and 3\n",
    "this_axs = axs[0, 1]  # Row 0, column 1\n",
    "this_axs.plot(dates_cty, clay_confirmed, label='Clay County')\n",
    "this_axs.plot(dates_cty, cass_confirmed, label='Cass County')\n",
    "legend = this_axs.legend()\n",
    "xlabel = this_axs.set_xlabel(\"Date\")\n",
    "ylabel = this_axs.set_ylabel(\"Number\")\n",
    "title = this_axs.set_title(\"COVID Confirmed Infections\")\n",
    "\n",
    "this_axs = axs[1, 1]  # Row 1, column 1\n",
    "this_axs.plot(dates_cty, clay_confirmed_rate, label='Clay County')\n",
    "this_axs.plot(dates_cty, cass_confirmed_rate, label='Cass County')\n",
    "legend = this_axs.legend()\n",
    "xlabel = this_axs.set_xlabel(\"Date\")\n",
    "ylabel = this_axs.set_ylabel(\"Rate / 100000 people\")\n",
    "title = this_axs.set_title(\"COVID Confirmed Infections per 100,000 people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# I will pull the data to plot into numpy arrays (notice I have to use [0] because it comes out at list of lists even for single row)\n",
    "#\n",
    "\n",
    "# State-level data for plotting\n",
    "dates_state = np.array(combined_state_df[(combined_state_df['FIPS'] == MNFIPS)]['Dates'].to_list()[0], dtype='datetime64')\n",
    "MN_deaths = np.array(combined_state_df[(combined_state_df['FIPS'] == MNFIPS)]['Deaths'].to_list()[0],dtype='int')\n",
    "MN_death_rate = (MN_deaths/combined_state_df[(combined_state_df['FIPS'] == MNFIPS)]['PopEst2019'].values)*100000\n",
    "ND_deaths = np.array(combined_state_df[(combined_state_df['FIPS'] == NDFIPS)]['Deaths'].to_list()[0],dtype='int')\n",
    "ND_death_rate = (ND_deaths/combined_state_df[(combined_state_df['FIPS'] == NDFIPS)]['PopEst2019'].values)*100000\n",
    "MN_confirmed = np.array(combined_state_df[(combined_state_df['FIPS'] == MNFIPS)]['Confirmed'].to_list()[0],dtype='int')\n",
    "MN_confirmed_rate = (MN_confirmed/combined_state_df[(combined_state_df['FIPS'] == MNFIPS)]['PopEst2019'].values)*100000\n",
    "ND_confirmed = np.array(combined_state_df[(combined_state_df['FIPS'] == NDFIPS)]['Confirmed'].to_list()[0],dtype='int')\n",
    "ND_confirmed_rate = (ND_confirmed/combined_state_df[(combined_state_df['FIPS'] == NDFIPS)]['PopEst2019'].values)*100000\n",
    "\n",
    "# Set up a figure of 2 x 2 plots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15,10))\n",
    "\n",
    "# Plot up deaths and death rates as plots 0 and 1\n",
    "this_axs = axs[0, 0]  # Row 0, column 0\n",
    "this_axs.plot(dates_state, MN_deaths, label='Minnesota')\n",
    "this_axs.plot(dates_state, ND_deaths, label='North Dakota')\n",
    "legend = this_axs.legend()\n",
    "xlabel = this_axs.set_xlabel(\"Date\")\n",
    "ylabel = this_axs.set_ylabel(\"Number\")\n",
    "title = this_axs.set_title(\"COVID Deaths\")\n",
    "\n",
    "this_axs = axs[1, 0]  # Row 1, column 0\n",
    "this_axs.plot(dates_state, MN_death_rate, label='Minnesota')\n",
    "this_axs.plot(dates_state, ND_death_rate, label='North Dakota')\n",
    "legend = this_axs.legend()\n",
    "xlabel = this_axs.set_xlabel(\"Date\")\n",
    "ylabel = this_axs.set_ylabel(\"Rate / 100000 people\")\n",
    "title = this_axs.set_title(\"COVID Deaths per 100,000 people\")\n",
    "\n",
    "# Plot up confirmed infections and infection rates as plots 2 and 3\n",
    "this_axs = axs[0, 1]  # Row 0, column 1\n",
    "this_axs.plot(dates_state, MN_confirmed, label='Minnesota')\n",
    "this_axs.plot(dates_state, ND_confirmed, label='North Dakota')\n",
    "legend = this_axs.legend()\n",
    "xlabel = this_axs.set_xlabel(\"Date\")\n",
    "ylabel = this_axs.set_ylabel(\"Number\")\n",
    "title = this_axs.set_title(\"COVID Confirmed Infections\")\n",
    "\n",
    "this_axs = axs[1, 1]  # Row 1, column 1\n",
    "this_axs.plot(dates_state, MN_confirmed_rate, label='Minnesota')\n",
    "this_axs.plot(dates_state, ND_confirmed_rate, label='North Dakota')\n",
    "legend = this_axs.legend()\n",
    "xlabel = this_axs.set_xlabel(\"Date\")\n",
    "ylabel = this_axs.set_ylabel(\"Rate / 100000 people\")\n",
    "title = this_axs.set_title(\"COVID Confirmed Infections per 100,000 people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show demonstrations of plotting this data here by producing plots of data for Cass and Clay counties and North Dakota and Minnesota\n",
    "\n",
    "#\n",
    "# I will pull the data to plot into numpy arrays (notice I have to use [0] because it comes out at list of lists even for single row)\n",
    "#\n",
    "\n",
    "# County-level data for plotting\n",
    "dates_cty = np.array(combined_cnty_df[(combined_cnty_df['FIPS'] == ClayFIPS)]['Dates'].to_list()[0], dtype='datetime64')\n",
    "clay_ddeaths = np.array(combined_cnty_df[(combined_cnty_df['FIPS'] == ClayFIPS)]['dDeaths'].to_list()[0])\n",
    "cass_ddeaths = np.array(combined_cnty_df[(combined_cnty_df['FIPS'] == CassFIPS)]['dDeaths'].to_list()[0])\n",
    "clay_dconfirmed = np.array(combined_cnty_df[(combined_cnty_df['FIPS'] == ClayFIPS)]['dConfirmed'].to_list()[0])\n",
    "cass_dconfirmed = np.array(combined_cnty_df[(combined_cnty_df['FIPS'] == CassFIPS)]['dConfirmed'].to_list()[0])\n",
    "\n",
    "# State-level data for plotting\n",
    "dates_state = np.array(combined_state_df[(combined_state_df['FIPS'] == MNFIPS)]['Dates'].to_list()[0], dtype='datetime64')\n",
    "MN_ddeaths = np.array(combined_state_df[(combined_state_df['FIPS'] == MNFIPS)]['dDeaths'].to_list()[0])\n",
    "ND_ddeaths = np.array(combined_state_df[(combined_state_df['FIPS'] == NDFIPS)]['dDeaths'].to_list()[0])\n",
    "MN_dconfirmed = np.array(combined_state_df[(combined_state_df['FIPS'] == MNFIPS)]['dConfirmed'].to_list()[0])\n",
    "ND_dconfirmed = np.array(combined_state_df[(combined_state_df['FIPS'] == NDFIPS)]['dConfirmed'].to_list()[0])\n",
    "\n",
    "# Set up a figure of 2 x 2 plots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 15))\n",
    "\n",
    "# Plot up the deriviates in the infection and death rates for counties\n",
    "this_axs = axs[0, 0]  # row 0, column 0\n",
    "this_axs.plot(dates_cty, clay_dconfirmed, label='Clay County')\n",
    "this_axs.plot(dates_cty, cass_dconfirmed, label='Cass County')\n",
    "legend = this_axs.legend()\n",
    "xlabel = this_axs.set_xlabel(\"Date\")\n",
    "ylabel = this_axs.set_ylabel(\"New Infections/Day\")\n",
    "title = this_axs.set_title(\"COVID Infection Change Rate\")\n",
    "\n",
    "this_axs = axs[0, 1]  # row 0, column 1\n",
    "this_axs.plot(dates_cty, clay_ddeaths, label='Clay County')\n",
    "this_axs.plot(dates_cty, cass_ddeaths, label='Cass County')\n",
    "legend = this_axs.legend()\n",
    "xlabel = this_axs.set_xlabel(\"Date\")\n",
    "ylabel = this_axs.set_ylabel(\"New Deaths/Day\")\n",
    "title = this_axs.set_title(\"COVID Death Change Rate\")\n",
    "\n",
    "# Plot up the deriviates in the infection and death rates for states\n",
    "this_axs = axs[1, 0]  # row 1, column 0\n",
    "this_axs.plot(dates_state, MN_dconfirmed, label='Minnesota')\n",
    "this_axs.plot(dates_state, ND_dconfirmed, label='North Dakota')\n",
    "legend = this_axs.legend()\n",
    "xlabel = this_axs.set_xlabel(\"Date\")\n",
    "ylabel = this_axs.set_ylabel(\"New Infections/Day\")\n",
    "title = this_axs.set_title(\"COVID Infection Change Rate\")\n",
    "\n",
    "this_axs = axs[1, 1]  # row 1, column 1\n",
    "this_axs.plot(dates_state, MN_ddeaths, label='Minnesota')\n",
    "this_axs.plot(dates_state, ND_ddeaths, label='North Dakota')\n",
    "legend = this_axs.legend()\n",
    "xlabel = this_axs.set_xlabel(\"Date\")\n",
    "ylabel = this_axs.set_ylabel(\"New Deaths/Day\")\n",
    "title = this_axs.set_title(\"COVID Death Change Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Mobility Data (FIPS cross-identification performed)\n",
    "\n",
    "This data is described at https://www.google.com/covid19/mobility/ and can be downloaded in a single monolithic CSV file at https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv\n",
    "\n",
    "> The data shows how visitors to (or time spent in) categorized places change compared to our baseline days. A baseline day represents a normal value for that day of the week. The baseline day is the median value from the 5‑week period Jan 3 – Feb 6, 2020.\n",
    "\n",
    "> For each region-category, the baseline isn’t a single value—it’s 7 individual values. The same number of visitors on 2 different days of the week, result in different percentage changes. So, we recommend the following:\n",
    "1. Don’t infer that larger changes mean more visitors or smaller changes mean less visitors.\n",
    "2. Avoid comparing day-to-day changes. Especially weekends with weekdays. (https://support.google.com/covid19-mobility/answer/9824897?hl=en&ref_topic=9822927)\n",
    "\n",
    "> Note, *Parks* typically means official national parks and not the general outdoors found in rural areas.\n",
    "\n",
    "Also, I'll note that aggregated national data appears to be available by setting `sub_region_1` **and** `sub_region_2` to `NaN` and state-level data by setting only `sub_region_2` to `NaN`.\n",
    "\n",
    "**Note to Developers:** Check the `date` column in the reduced data to see if it is a real match or just a marker for a non-match.  Furthermore be away Google has a lot of blank (`NaN`) entries in a lot of columns and variable numbers of entries for each county/state.\n",
    "\n",
    "\n",
    "**Suggested Citation**: Google LLC \"Google COVID-19 Community Mobility Reports\". https://www.google.com/covid19/mobility/ Accessed: `<Date>.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the Google Mobility dataframes\n",
    "(goog_mobility_cnty_df, goog_mobility_states_df) = COVID.retrieve_goog_mobility_data(cnty_pop_df, state_pop_df)\n",
    "\n",
    "# Export the google mobility data to CSV files\n",
    "print(\"Exporting Google mobility data\")\n",
    "    \n",
    "goog_mobility_cnty_fname = data_dir + \"goog_mobility_cnty.csv\"\n",
    "print(\" - Google county level mobility data exported to \", goog_mobility_cnty_fname)\n",
    "goog_mobility_cnty_df.to_csv(goog_mobility_cnty_fname, index=False)\n",
    "\n",
    "goog_mobility_states_fname = data_dir + \"goog_mobility_state.csv\"\n",
    "print(\" - Google state level mobility data exported to \", goog_mobility_states_fname)\n",
    "goog_mobility_states_df.to_csv(goog_mobility_states_fname, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apple Mobility Data  (FIPS cross-identification performed)\n",
    "\n",
    "This data is described at https://www.apple.com/covid19/mobility.\n",
    "\n",
    "**About this Data (copied from Apple's site)**: The CSV file on this site show a relative volume of directions requests per country/region, sub-region or city compared to a baseline volume on January 13th, 2020. We define our day as midnight-to-midnight, Pacific time. Cities are defined as the greater metropolitan area and their geographic boundaries remain constant across the data set. In many countries/regions, sub-regions, and cities, relative volume has increased since January 13th, consistent with normal, seasonal usage of Apple Maps. Day of week effects are important to normalize as you use this data. Data that is sent from users’ devices to the Maps service is associated with random, rotating identifiers so Apple doesn’t have a profile of individual movements and searches. Apple Maps has no demographic information about our users, so we can’t make any statements about the representativeness of usage against the overall population.\n",
    "\n",
    "Apple tracks three kinds of Apple Maps routing requests: Driving, Walking, Transit.  But the only data available at the state and county level is the Driving data.\n",
    "\n",
    "**Developer Notes**: While Apple has fewer blank (`NaN`) entries when a county was included (versus Google data), Apple's mobility data only exists for 2090 out of 3142 counties in the US. Counties with no published data are in this dataframe as `NaN` for both dates and driving mobility information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the Apple Mobility dataframes\n",
    "(aapl_mobility_cnty_df, aapl_mobility_states_df) = COVID.retrieve_aapl_mobility_data(cnty_pop_df, state_pop_df)\n",
    "\n",
    "# Notice only driving information is available at the county level here\n",
    "print(\"APPLE MOBILITY DATA IN aapl_mobility_cnty_df() FOR CLAY COUNTY\")\n",
    "aapl_mobility_clay = aapl_mobility_cnty_df[(aapl_mobility_cnty_df['county'] == 'Clay County') & (aapl_mobility_cnty_df['state'] == 'Minnesota')]\n",
    "print(aapl_mobility_clay)\n",
    "    \n",
    "# Export the Apple mobility data to CSV files\n",
    "print(\"\\nExporting Apple mobility data\")\n",
    "    \n",
    "aapl_mobility_cnty_fname = data_dir + \"aapl_mobility_cnty.csv\"\n",
    "print(\" - Apple county level mobility data exported to \", aapl_mobility_cnty_fname)\n",
    "aapl_mobility_cnty_df.to_csv(aapl_mobility_cnty_fname, index=False)\n",
    "\n",
    "aapl_mobility_states_fname = data_dir + \"aapl_mobility_state.csv\"\n",
    "print(\" - Apple state level mobility data exported to \", aapl_mobility_states_fname)\n",
    "aapl_mobility_states_df.to_csv(aapl_mobility_states_fname, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Institute for Health Metrics and Evaluation (IMHE) Data on Local Resources  (FIPS cross-identification performed)\n",
    "\n",
    "There is Institute for Health Metrics and Evaluation data on local resources at http://www.healthdata.org/covid/data-downloads although data only has state level resolution. \n",
    "\n",
    "**Suggested Citation**: Institute for Health Metrics and Evaluation (IHME). COVID-19 Hospital Needs and Death Projections. Seattle, United States of America: Institute for Health Metrics and Evaluation (IHME), University of Washington, 2020.\n",
    "\n",
    "**Note to Developers:** IMHE data has a few blank (`NaN`) entries for dates, presumably reflecting unknown values.  Also, some of the dates are from 2019, which suggests no known values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve IMHE data\n",
    "(imhe_summary, imhe_hospitalizations) = COVID.retrieve_imhe_data(cnty_pop_df, state_pop_df)\n",
    "\n",
    "## Summary data includes numbers or dates for the following for each state\n",
    "#             'peak_bed_day_mean', 'peak_bed_day_lower', 'peak_bed_day_upper': Mean/Lower/Upper Uncertainty peak bed use date\n",
    "# 'peak_icu_bed_day_mean', 'peak_icu_bed_day_lower', 'peak_icu_bed_day_upper': Mean/Lower/Upper Uncertainty ICU bed use date\n",
    "#          'peak_vent_day_mean', 'peak_vent_day_lower', 'peak_vent_day_upper': Mean/Lower/Upper Uncertainty Ventilator use date\n",
    "#    'all_bed_capacity', 'icu_bed_capacity', 'all_bed_usage', 'icu_bed_usage': Number of beds/ICU beds/avg beds used/avg ICU beds used\n",
    "#                          'travel_limit_start_date', 'travel_limit_end_date': Severe travel restrictions start/end dates\n",
    "#                                'stay_home_start_date', 'stay_home_end_date': Stay at home order start/end dates\n",
    "#                    'educational_fac_start_date', 'educational_fac_end_date': Educational facilities closure start/end dates\n",
    "#      'any_gathering_restrict_start_date', 'any_gathering_restrict_end_date': Any gathering restrictions start/end dates\n",
    "#                          'any_business_start_date', 'any_business_end_date': Any business closures start/end dates\n",
    "#          'all_non-ess_business_start_date', 'all_non-ess_business_end_date': Non-essential businesses ordered to close start/end dates\n",
    "#\n",
    "# 'NaN' present for dates means it isn't known.\n",
    "\n",
    "## Hospitalization data is time series date for the following projections by the IMHE:\n",
    "#                             'allbed_mean', 'allbed_lower','allbed_upper': Predicted COVID beds needed with upper/lower bounds\n",
    "#                            'ICUbed_mean', 'ICUbed_lower', 'ICUbed_upper': Predicted COVID ICU beds needed with upper/lower bounds\n",
    "#                            'InvVen_mean', 'InvVen_lower', 'InvVen_upper': Predicted COVID ventilators needed with upper/lower bounds\n",
    "#                            'deaths_mean', 'deaths_lower', 'deaths_upper': Predicted COVID daily deaths with upper/lower bounds\n",
    "#                               'admis_mean', 'admis_lower', 'admis_upper': Predicted hospital admissions with upper/lower bounds\n",
    "#                            'newICU_mean', 'newICU_lower', 'newICU_upper': Predicted new ICU admissions per day with upper/lower bounds\n",
    "#                            'totdea_mean', 'totdea_lower', 'totdea_upper': Predicted COVID cumilative deaths with upper/lower bounds\n",
    "# 'deaths_mean_smoothed', 'deaths_lower_smoothed', 'deaths_upper_smoothed': Smoothed version of predicted COVID daily deaths\n",
    "# 'totdea_mean_smoothed', 'totdea_lower_smoothed', 'totdea_upper_smoothed': Smoothed version of cumilative COVID deaths\n",
    "#                                   'total_tests_data_type', 'total_tests': observed/predicted tests and total number of tests\n",
    "#                                                   'confirmed_infections': Observed confirmed infections only\n",
    "#    'est_infections_mean', 'est_infections_lower', 'est_infections_upper': Predicted estimated infections with upper/lower bounds\n",
    "#\n",
    "# 'NaN' present for dates means it isn't known.\n",
    "\n",
    "# Write out CSV files to disk\n",
    "imhe_summary_fname = data_dir + \"imhe_summary.csv\"\n",
    "print(\" - IMHE state level summary data exported to \", imhe_summary_fname)\n",
    "imhe_summary.to_csv(imhe_summary_fname, index=False)\n",
    "\n",
    "imhe_hospitalizations_fname = data_dir + \"imhe_hospitalizations.csv\"\n",
    "print(\" - IMHE hospitalization level summary data exported to \", imhe_summary_fname)\n",
    "imhe_hospitalizations.to_csv(imhe_hospitalizations_fname, index=False)\n",
    "\n",
    "# Present summary data for local area\n",
    "print(\"\\nIMHE SUMMARY DATA IN imhe_summary() FOR MN and ND\")\n",
    "imhe_summary_local = imhe_summary[(imhe_summary.FIPS == MNFIPS) | (imhe_summary.FIPS == NDFIPS) ]\n",
    "print(imhe_summary_local)\n",
    "\n",
    "# Present summary data for local area\n",
    "print(\"\\nIMHE SUMMARY DATA IN imhe_hospitalizations() FOR MN and ND\")\n",
    "imhe_hospitalizations_local = imhe_hospitalizations[(imhe_hospitalizations.FIPS == MNFIPS) | (imhe_hospitalizations.FIPS == NDFIPS) ]\n",
    "print(imhe_hospitalizations_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NY Times Data on Probable Deaths/Cases (FIPS Present, NOT CURRENTLY USED FOR PROJECT)\n",
    "\n",
    "The NY Times has assembled data on COVID in a GitHub repository at https://github.com/nytimes/covid-19-data.  I have not examined that data yet, but it may well be interesting.\n",
    "\n",
    "Note their statement requiring credit:\n",
    "\n",
    "> In light of the current public health emergency, The New York Times Company is\n",
    "providing this database under the following free-of-cost, perpetual,\n",
    "non-exclusive license. Anyone may copy, distribute, and display the database, or\n",
    "any part thereof, and make derivative works based on it, provided  (a) any such\n",
    "use is for non-commercial purposes only and (b) credit is given to The New York\n",
    "Times in any public display of the database, in any publication derived in part\n",
    "or in full from the database, and in any other public use of the data contained\n",
    "in or derived from the database.\n",
    "\n",
    "Data is available at county, state, and national levels for live numbers (current cases/deaths as well as probable cases/deaths, updated daily).  That said, at least locally I don't think Probable cases are really making a difference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Retrieve the NYT datafiles to see what is there that might be of interest\n",
    "##\n",
    "\n",
    "# Update the NYT Datafiles\n",
    "NYTdata_dir = \"NYT_Data/\"\n",
    "g = git.cmd.Git(NYTdata_dir)\n",
    "# We should check status to see everything is good eventually, \n",
    "# for now, I am using this to hide the status message from GitPython module\n",
    "status = g.pull()  \n",
    "\n",
    "# Grab the live data files\n",
    "live_county_csv = NYTdata_dir+\"live/us-counties.csv\"\n",
    "live_state_csv = NYTdata_dir+\"live/us-states.csv\"\n",
    "live_us_csv = NYTdata_dir+\"live/us.csv\"\n",
    "\n",
    "# Create pandas dataframes containing the daily data from the CSV files (contains number of confirmed/deaths/recovered on that date)\n",
    "live_county_df = pd.read_csv(live_county_csv)   # County totals\n",
    "live_state_df = pd.read_csv(live_state_csv)    # State totals\n",
    "live_us_df = pd.read_csv(live_us_csv)       # National totals\n",
    "\n",
    "# Print county data to screen\n",
    "print(\"LOCAL COUNTY DATA IN live_county_df() DATAFRAME\")\n",
    "print(live_county_df[ (live_county_df['fips'] == ClayFIPS) | (live_county_df['fips'] == CassFIPS) ])\n",
    "\n",
    "# Print state level data to screen\n",
    "print(\"\\nLOCAL STATE DATA IN live_state_df() DATAFRAME\")\n",
    "print(live_state_df[ (live_state_df['fips'] == MNFIPS) | (live_state_df['fips'] == NDFIPS) ])\n",
    "\n",
    "# Print national data\n",
    "print(\"\\nNATIONAL DATA IN live_us_df() DATAFRAME\")\n",
    "print(live_us_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
