{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Prototype) COVID Dashboard Map\n",
    "\n",
    "This is a prototype COVID Dashboard for testing displaying COVID data on maps (initially testing using the folium library)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This forces a reload of any external library file if it changes.  \n",
    "# Useful when developing external libraries since otherwise Jupyter \n",
    "# will not re-import any library without restarting the python kernel.\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Import COVID IO routines from external python libraries\n",
    "import COVIDlib.data_IO as COVID_IO\n",
    "import COVIDlib.dashboard_IO as COVID_Dash\n",
    "\n",
    "# imports for ipyleaflet \n",
    "import ipyleaflet as lf\n",
    "import json\n",
    "from branca.colormap import linear\n",
    "\n",
    "## Define variables of interest below\n",
    "data_dir = 'our_data/'    # Data directory for the COVID datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Preprocessing COVID Dataset ... Done (1.50 sec)\n"
     ]
    }
   ],
   "source": [
    "# Load all the dataframes into memory\n",
    "print(\"Loading and Preprocessing COVID Dataset ... \", end='')\n",
    "\n",
    "start= time.perf_counter()\n",
    "# Retrieve John Hopkins dataframes and add \"rates\" of deaths/infections\n",
    "(JH_state_df, JH_cnty_df) = COVID_IO.PtoCDRDataFrames()\n",
    "JH_state_df = COVID_Dash.cleanJHdata(JH_state_df)\n",
    "JH_cnty_df = COVID_Dash.cleanJHdata(JH_cnty_df)\n",
    "\n",
    "# Construct dictionary of FIPS values by placename\n",
    "FIPSd = COVID_Dash.build_fipsdict(JH_cnty_df, JH_state_df)\n",
    "\n",
    "# Retrieve Apple Mobility Dataframe\n",
    "(aapl_cnty_df, aapl_state_df) = COVID_IO.PtoAAPLMobilityDataFrames()\n",
    "COVID_Dash.cleanAAPLdata(aapl_cnty_df)\n",
    "COVID_Dash.cleanAAPLdata(aapl_state_df)\n",
    "\n",
    "# Retrieve Google Mobility Dataframe\n",
    "(goog_cnty_df, goog_state_df) = COVID_IO.PtoGOOGMobilityDataFrames()\n",
    "\n",
    "# Retrieve IMHE Dataframes\n",
    "(summary_df, hospitalization_df) = COVID_IO.PtoIMHEDataFrames()\n",
    "\n",
    "end= time.perf_counter()\n",
    "\n",
    "print(f\"Done ({end-start:0.2f} sec)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This initial test version is based on a prototype seen at https://python-graph-gallery.com/292-choropleth-map-with-folium/\n",
    "\n",
    "# # Location of JSON with the shapes of the US states (note in this JSON, the \"id\" field [used to match to data] consists of 2 letter postal codes [e.g. MN or ND])\n",
    "# state_geo = './folium_jsons/us-states.json'\n",
    "\n",
    "# # Location of JSON with the shapes of the US counties (only has four keys, none are ID, don't know if it is just stored in FIPS number order)\n",
    "# county_geo = './folium_jsons/us_counties_20m_topo.json'\n",
    "\n",
    "# Grab only the state data and then redefine columns to have only last day's data\n",
    "state_data = JH_state_df[JH_state_df['state'] != 'United States'].set_index('postal').copy()\n",
    "\n",
    "state_data['ConfirmedRate'] = np.array(state_data['ConfirmedRate'].to_list())[:,-1].tolist()\n",
    "state_data['DeathsRate'] = np.array(state_data['DeathRate'].to_list())[:,-1].tolist()\n",
    "state_data['dConfirmedRate'] = np.array(state_data['dConfirmedRate'].to_list())[:,-1].tolist()\n",
    "state_data['dDeathsRate'] = np.array(state_data['dDeathsRate'].to_list())[:,-1].tolist()\n",
    "state_data['d2ConfirmedRate'] = np.array(state_data['d2ConfirmedRate'].to_list())[:,-1].tolist()\n",
    "state_data['d2DeathsRate'] = np.array(state_data['d2DeathsRate'].to_list())[:,-1].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_data = JH_cnty_df.set_index('FIPS').copy()  # Index by FIPS in this copy of the county data\n",
    "\n",
    "# only retain the most recent value in these columns\n",
    "county_data['ConfirmedRate'] = np.array(county_data['ConfirmedRate'].to_list())[:,-1].tolist()\n",
    "county_data['DeathsRate'] = np.array(county_data['DeathRate'].to_list())[:,-1].tolist()\n",
    "county_data['dConfirmedRate'] = np.array(county_data['dConfirmedRate'].to_list())[:,-1].tolist()\n",
    "county_data['dDeathsRate'] = np.array(county_data['dDeathsRate'].to_list())[:,-1].tolist()\n",
    "county_data['d2ConfirmedRate'] = np.array(county_data['d2ConfirmedRate'].to_list())[:,-1].tolist()\n",
    "county_data['d2DeathsRate'] = np.array(county_data['d2DeathsRate'].to_list())[:,-1].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Maps using iPyLeaflet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipyleaflet map testing below\n",
    "# The reason for using ipyleaflet is that it directly supports widgets\n",
    "# Luke's to do: get JSON data to work, add choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Define useful functions for building Map data\n",
    "\n",
    "def load_statedata(filename = './ipyleaflet_json/us-states.json', file_type=json.load ):\n",
    "    # Define this function for loading the state boundaries JSON (grabbed from the GitHub repo for iPyLeaflet)\n",
    "    with open(filename, 'r') as f:\n",
    "        # Had to set the encoding for this import to work on Mac (should still work on PC)\n",
    "        return file_type(f)\n",
    "    \n",
    "\n",
    "def load_countydata(filename = './ipyleaflet_json/gz_2010_us_050_00_20m.json', file_type=json.load ):\n",
    "    # Define this function for loading the county boundaries JSON file which was originally\n",
    "    # grabbed from https://github.com/kjhealy/us-county\n",
    "    with open(filename, 'r', encoding=\"ISO-8859-1\") as f:\n",
    "        # Had to set the encoding for this import to work on Mac (should still work on PC)\n",
    "        return file_type(f)\n",
    "\n",
    "\n",
    "def format_cnty_dict(dataframe):\n",
    "    # ipyleaflet expects dictionaries of data, keyed by the ID, so converting county data to be right format\n",
    "    data_dict = {}\n",
    "    for key in dataframe.to_dict():\n",
    "        if key < 10000:\n",
    "            newKey = '0500000US0' + str(key)\n",
    "            data_dict[newKey] = dataframe[key]\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def format_state_dict(dataframe):\n",
    "    # ipyleaflet expects dictionaries of data, keyed by the ID, so converting state pandas dataframe into dictionary\n",
    "    return dataframe.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads a county border json file useful for ipyleaflet since the county \n",
    "# JSON that comes with folium doesn't have a 'properties' field, which (I think) ipyleaflet requires for choropleths\n",
    "geo_json_data = load_countydata()\n",
    "geo_json_states_data = load_statedata()\n",
    "\n",
    "# Pick the data series to plot\n",
    "state_data_series = state_data['dConfirmedRate']\n",
    "county_data_series = county_data['dConfirmedRate']\n",
    "\n",
    "# ipyleaflet requires a dictionary for the choro_data field/the variable to be visualized, so convert the Pandas data series\n",
    "# into the appropriate dictionary (handling the conversion of the FIPS indices to the keys used in county JSON data)\n",
    "county_data_dict = format_cnty_dict(county_data_series)\n",
    "state_data_dict = format_state_dict(state_data_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16bd5059079a414885c6ddbf6b66bd5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[38.0, -93.0], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_ouâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define map center and zoom\n",
    "center = [38.0, -93.0]\n",
    "zoom = 3.9\n",
    "\n",
    "# Determine range of values for colormap, then define colormap\n",
    "minval = state_data_series.min()\n",
    "maxval = state_data_series.max()\n",
    "cmap=linear.YlOrRd_04.scale(minval,maxval)\n",
    "\n",
    "# Break range into steps to build colormap legend dictionary\n",
    "nsteps = 5\n",
    "step = (maxval-minval)/(nsteps-1)\n",
    "legendDict = {}\n",
    "for i in range(nsteps):\n",
    "    val = minval+i*step\n",
    "    valstr = f\"{val:,.1f}\"\n",
    "    legendDict[valstr] = cmap(val)\n",
    "\n",
    "# Creating the map\n",
    "test_map = lf.Map(center = center, zoom = zoom)\n",
    "    \n",
    "# Draw a functional states layer\n",
    "states_layer = lf.Choropleth(geo_data=geo_json_states_data,\n",
    "                             choro_data=state_data_dict,\n",
    "                             key_on='id',\n",
    "                             # Below here is some formatting/coloring from the documentation\n",
    "                             colormap=cmap,\n",
    "                             border_color='black',\n",
    "                             style={'fillOpacity': 0.8, 'dashArray': '5, 5'} )\n",
    "test_map.add_layer(states_layer)\n",
    "\n",
    "# Display a legend    \n",
    "legend = lf.LegendControl(legendDict, name=\"Legend\", position=\"topright\")\n",
    "test_map.add_control(legend)\n",
    "\n",
    "# Display map\n",
    "display(test_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should now attempt a county plot again, although I suspect we will have to manipulate the county_data_dict dictionary \n",
    "# to get it into a format ipyleaflet will understand.  Possibly simply copying GEO_ID to id in the proper place in the dictionary?\n",
    "\n",
    "# Example of contents of the county GEOJSON data structure (NOT CURRENTLY WORKING)\n",
    "# {'type': 'FeatureCollection',\n",
    "#  'features': [{'type': 'Feature',\n",
    "#    'properties': {'GEO_ID': '0500000US01001',\n",
    "#     'STATE': '01',\n",
    "#     'COUNTY': '001',\n",
    "#     'NAME': 'Autauga',\n",
    "#     'LSAD': 'County',\n",
    "#     'CENSUSAREA': 594.436},\n",
    "#    'geometry': {'type': 'Polygon',\n",
    "#     'coordinates': [[[-86.496774, 32.344437],\n",
    "#       [-86.717897, 32.402814],\n",
    "#       [-86.814912, 32.340803],\n",
    "#       [-86.890581, 32.502974],\n",
    "#       [-86.917595, 32.664169],\n",
    "#       [-86.71339, 32.661732],\n",
    "#       [-86.714219, 32.705694],\n",
    "#       [-86.413116, 32.707386],\n",
    "#       [-86.411172, 32.409937],\n",
    "#       [-86.496774, 32.344437]]]}},\n",
    "\n",
    "# Example of contents of state GEOJSON data structure (WHICH DOES WORK)\n",
    "# {'type': 'FeatureCollection',\n",
    "#  'features': [{'type': 'Feature',\n",
    "#    'id': 'AL',\n",
    "#    'properties': {'name': 'Alabama'},\n",
    "#    'geometry': {'type': 'Polygon',\n",
    "#     'coordinates': [[[-87.359296, 35.00118],\n",
    "#       [-85.606675, 34.984749],\n",
    "#       [-85.431413, 34.124869],\n",
    "#       [-85.184951, 32.859696],\n",
    "#       [-85.069935, 32.580372],\n",
    "#       [-84.960397, 32.421541],\n",
    "\n",
    "# I suspect if we moved the GEO_ID (or simply copied it) to the features level as id, it might work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
